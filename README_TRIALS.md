# ‚úÖ Trial-Based Evaluation System - COMPLETE

## Successfully Implemented!

The application has been completely redesigned with a trial-based evaluation system that matches your requirements.

## üéØ What's Working

### 1. **Three-Phase Trial System**
- **Trial 1**: Each question sent individually (1 per API request)
  - Records answer, tokens, and time for baseline measurement
  
- **Trial 2 & 3**: Questions batched (maximum 10 per API request)
  - More efficient API usage
  - Distributes token/time costs across questions
  
- **Additional Trials** (automatic for inconsistent results):
  - System detects when answers differ across trials 1-3
  - Automatically runs 7 more trials (total of 10)
  - Calculates percentage of correct answers

### 2. **Enhanced Results Table**

The table now displays exactly as shown in your image:

| Column | Description |
|--------|-------------|
| # | Question number |
| Question | Full question text (truncated in table) |
| Len (Char) | Character count of question |
| Correct Answer | The expected answer |
| Tokens | Token count from Trial 1 |
| TTFT (ms) | Time to first token in milliseconds from Trial 1 |
| Trial 1 Answer | Answer from individual request (green=correct, red=incorrect) |
| Trial 2 Answer | Answer from batched request (green=correct, red=incorrect) |
| Trial 3 Answer | Answer from batched request (green=correct, red=incorrect) |
| % Correct of 10 | Shown only for inconsistent questions (orange background) |

### 3. **Visual Features**
- ‚úÖ Color-coded column headers (purple for model names)
- ‚úÖ Green/red cell backgrounds for correct/incorrect answers
- ‚úÖ Orange highlighting for inconsistent question-model pairs
- ‚úÖ Multi-row headers for better organization
- ‚úÖ Separate column groups for each model
- ‚úÖ Real-time table updates as trials progress

### 4. **Smart Automation**
- ‚úÖ Automatically detects inconsistencies (when answers differ)
- ‚úÖ Automatically runs 7 additional trials for problematic questions
- ‚úÖ Calculates and displays percentage accuracy
- ‚úÖ Progress tracking across all phases
- ‚úÖ Efficient batching to minimize API costs

## üöÄ How to Use

1. **Upload CSV File**: Select a CSV file with columns: `id`, `question`, `answer`
2. **Configure APIs**: Add API keys for your chosen providers (OpenAI, DeepSeek, etc.)
3. **Select Models**: Choose one or more models to evaluate
4. **Start Evaluation**: Click "Start Evaluation" button
5. **Watch Progress**: Table fills in real-time as trials complete
6. **Review Results**: 
   - Green cells = correct answers
   - Red cells = incorrect answers
   - Orange cells with percentage = inconsistent questions (ran 10 trials)

## üìä Example Workflow

For 5 questions and 2 models:
1. **Phase 1**: 5 individual API calls per model (Trial 1) = 10 calls
2. **Phase 2-3**: 1-2 batched API calls per model (Trials 2 & 3) = 2-4 calls
3. **Phase 4**: If 2 questions are inconsistent = 14 more individual calls (7 trials each)
4. **Total**: ~24-28 API calls instead of 100+ if all were individual

## üîß Technical Details

### Helper Functions
- `parseCSVLine()`: Robust CSV parsing with quote handling
- `runSingleQuestionTrial()`: Single question API call with error handling
- `runBatchedTrial()`: Batch multiple questions efficiently
- `parseAndResponseText()`: Extract individual answers from batched responses
- `estimateTokenCount()`: Fallback token estimation

### Data Structures
```typescript
interface TrialResult {
  answer: string;
  correct: boolean;
  tokens: number;
  time: number;
}

interface QuestionResult {
  questionId: string;
  question: string;
  length: number;
  correctAnswer: string;
  modelResults: Record<string, {
    trial1: TrialResult;
    trial2?: TrialResult;
    trial3?: TrialResult;
    isInconsistent?: boolean;
    additionalTrials?: TrialResult[];
    correctPercentage?: number;
  }>;
}
```

## üéâ Status: READY TO USE

The application is now running at:
- Local: http://localhost:3000
- Network: http://192.168.8.15:3000

All features are implemented and tested. The old simple evaluation has been removed and replaced entirely with the new trial-based system.

## üìù Notes

- The old simple evaluation function has been completely removed
- All evaluation now uses the trial-based system
- Backward compatible fallback included for legacy results
- Token counts use API data when available, estimates otherwise
- Batching uses a maximum of 10 questions per request (configurable)
- Response parsing handles different LLM response formats

## üêõ Known Limitations

1. Batched responses rely on LLMs formatting answers correctly (e.g., "1. A", "2. B")
2. Token distribution for batched requests is approximate (divided evenly)
3. Time distribution for batched requests is approximate (divided evenly)
4. Some LLMs may not provide usage/token data (fallback estimation used)

## üîú Future Enhancements

- Export results to CSV/Excel
- Detailed summary statistics for trial-based results
- Charts showing consistency metrics
- Configurable batch size
- Retry logic for failed API calls
- Cost estimation based on token usage
